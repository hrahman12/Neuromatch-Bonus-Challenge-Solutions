{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Definitions\n",
        "\n",
        "1. **Mean Squared Error (MSE):**\n",
        "   $$\\text{MSE} = \\mathbb{E}_X[(y - \\hat{y}(x;\\theta))^2]$$\n",
        "   \n",
        "2. **Bias:**\n",
        "   $$\\text{Bias}[\\hat{y}(x; \\theta)] = \\mathbb{E}_X[\\hat{y}(x; \\theta)] - y$$\n",
        "   \n",
        "3. **Variance:**\n",
        "   $$\\text{Var}_X[\\hat{y}(x; \\theta)] = \\mathbb{E}_X[\\hat{y}^2(x; \\theta)] - \\mathbb{E}_X[\\hat{y}(x; \\theta)]^2$$"
      ],
      "metadata": {
        "id": "JhN-DKpCdHPl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Decomposition Formula\n",
        "The MSE can be decomposed into the square of the bias, the variance of the estimator, and the irreducible error ($\\sigma^2$):\n",
        "\n",
        "$$\n",
        "\\text{MSE} = (\\text{Bias}[\\hat{y}(x; \\theta)])^2 + \\text{Var}_x[\\hat{y}(x; \\theta)] + \\sigma^2\n",
        "$$\n",
        "\n",
        "## Proof\n",
        "\n",
        "1. **Expand the MSE**:\n",
        "   Start by writing the MSE formula and then add and subtract the expected prediction:\n",
        "\n",
        "   $$\n",
        "   \\text{MSE} = E\\left[(y - \\hat{y}(x; \\theta))^2\\right] = E\\left[(y - E[\\hat{y}(x; \\theta)] + E[\\hat{y}(x; \\theta)] - \\hat{y}(x; \\theta))^2\\right]\n",
        "   $$\n",
        "\n",
        "2. **Apply expansion**:\n",
        "   Expand the square using the identity $(a + b)^2 = a^2 + 2ab + b^2$:\n",
        "\n",
        "   $$\n",
        "   \\text{MSE} = E\\left[(y - E[\\hat{y}(x; \\theta)])^2\\right] + 2E\\left[(y - E[\\hat{y}(x; \\theta)])(E[\\hat{y}(x; \\theta)] - \\hat{y}(x; \\theta))\\right] + E\\left[(E[\\hat{y}(x; \\theta)] - \\hat{y}(x; \\theta))^2\\right]\n",
        "   $$\n",
        "\n",
        "3. **Simplify cross-term**:\n",
        "   The middle term averages to zero since expectations of independent terms multiply:\n",
        "\n",
        "   $$\n",
        "   E\\left[(y - E[\\hat{y}(x; \\theta)])(E[\\hat{y}(x; \\theta)] - \\hat{y}(x; \\theta))\\right] = (y - E[\\hat{y}(x; \\theta)])E\\left[E[\\hat{y}(x; \\theta)] - \\hat{y}(x; \\theta)\\right] = 0\n",
        "   $$\n",
        "\n",
        "4. **Identify Bias and Variance**:\n",
        "   Use the definitions of Bias and Variance to recognize these terms in the expanded MSE:\n",
        "\n",
        "   $$\n",
        "   \\text{Bias}^2 = (E[\\hat{y}(x; \\theta)] - y)^2\n",
        "   $$\n",
        "   $$\n",
        "   \\text{Var}_x = E\\left[(\\hat{y}(x; \\theta) - E[\\hat{y}(x; \\theta)])^2\\right]\n",
        "   $$\n",
        "\n",
        "5. **Final Decomposition**:\n",
        "   Conclude that the MSE decomposes as follows:\n",
        "\n",
        "   $$\n",
        "   \\text{MSE} = \\text{Bias}^2 + \\text{Var}_x + \\sigma^2\n",
        "   $$"
      ],
      "metadata": {
        "id": "isnQlx8ceFcK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Code"
      ],
      "metadata": {
        "id": "RSj1OdBoe6e7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Simulate data\n",
        "np.random.seed(0)\n",
        "x = np.linspace(0, 1, 100)  # Features\n",
        "true_theta = np.array([1, 2])  # True parameters\n",
        "y = true_theta[0] + true_theta[1] * x + np.random.normal(0, 0.1, size=x.size)  # True model with noise\n",
        "\n",
        "# Function to simulate model predictions\n",
        "def simulate_predictions(x, true_theta, n_simulations=1000):\n",
        "    predictions = []\n",
        "    for _ in range(n_simulations):\n",
        "        noise = np.random.normal(0, 0.1, size=x.size)\n",
        "        predictions.append(true_theta[0] + true_theta[1] * x + noise)\n",
        "    predictions = np.array(predictions)\n",
        "    return predictions\n",
        "\n",
        "# Calculate Bias, Variance, MSE\n",
        "def calculate_bias_variance_mse(x, y, predictions):\n",
        "    # Expected prediction\n",
        "    expected_prediction = np.mean(predictions, axis=0)\n",
        "\n",
        "    # Bias (squared) - E_yhat - y\n",
        "    bias_squared = np.mean((expected_prediction - y) ** 2)\n",
        "\n",
        "    # Variance\n",
        "    variance = np.mean(np.var(predictions, axis=0))\n",
        "\n",
        "    # MSE\n",
        "    mse = np.mean((predictions - y.reshape(1, -1)) ** 2)\n",
        "\n",
        "    return bias_squared, variance, mse\n",
        "\n",
        "# Run simulation\n",
        "predictions = simulate_predictions(x, true_theta)\n",
        "bias_squared, variance, mse = calculate_bias_variance_mse(x, y, predictions)\n",
        "\n",
        "print(f\"Bias^2: {bias_squared:.4f}\")\n",
        "print(f\"Variance: {variance:.4f}\")\n",
        "print(f\"MSE: {mse:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Rp4E3bZe5qC",
        "outputId": "abd4bd39-2f47-4286-ccde-bd5e77dab6cd"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bias^2: 0.0102\n",
            "Variance: 0.0099\n",
            "MSE: 0.0201\n"
          ]
        }
      ]
    }
  ]
}